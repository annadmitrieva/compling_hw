{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f =\"unamb_sent_14_6.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import *\n",
    "reader = ConllCorpusReader(root = '', fileids = [f], columntypes = ['words','pos', 'tree', 'chunk', 'ne', 'ignore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=[]\n",
    "for i in reader.iob_sents():\n",
    "    for j in i:\n",
    "        text.append(j[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_text=open(\"training.txt\", encoding='utf-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_train=[]\n",
    "i=1\n",
    "while i<=len(more_text):\n",
    "    clean_train.append(more_text[i])\n",
    "    i+=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m=Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "clean_train_tokens=[]\n",
    "for i in clean_train:\n",
    "    if i[-2:]=='\\n':\n",
    "        s=i[:-2]+'.'\n",
    "        for t in nltk.word_tokenize(s):\n",
    "            print(t)\n",
    "            clean_train_tokens.append(t)\n",
    "    else:\n",
    "        s=i+'.'\n",
    "        for t in nltk.word_tokenize(s):\n",
    "            clean_train_tokens.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens=clean_train_tokens+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for chars\n",
    "all_bigrams={}\n",
    "all_unigrams={}\n",
    "for word in all_tokens:\n",
    "    word=word.lower()\n",
    "    word_bigrams=[word[k:k+2] for k in range(len(word)-1)]\n",
    "    for i in word_bigrams:\n",
    "        if i in all_bigrams.keys():\n",
    "            all_bigrams[i]+=1\n",
    "        else:\n",
    "            all_bigrams[i]=0\n",
    "    word_unigrams=[word[k:k+1] for k in range(len(word))]\n",
    "    for i in word_unigrams:\n",
    "        if i in all_unigrams.keys():\n",
    "            all_unigrams[i]+=1\n",
    "        else:\n",
    "            all_unigrams[i]=1\n",
    "            \n",
    "\n",
    "from alphabet_detector import AlphabetDetector\n",
    "ad = AlphabetDetector()\n",
    "ad.only_alphabet_chars(u\"кириллический\", \"CYRILLIC\")\n",
    "l1=len(all_bigrams)\n",
    "l2=len(all_unigrams)\n",
    "char_bigram_probs={}\n",
    "for i in all_bigrams.items():\n",
    "    for k, v in all_unigrams.items():\n",
    "        if ad.is_cyrillic(i[0]) and i[0].isdigit()==False and i[0][0] == k:\n",
    "            char_bigram_probs[i[0][0]+i[0][1]]=(i[1]/l1)/(v/l2)\n",
    "\n",
    "import datrie\n",
    "trie = datrie.Trie('йцукенгшщзхъфывапролджэячсмитьбю -ё')\n",
    "for k, v in char_bigram_probs.items():\n",
    "    trie[k]=v\n",
    "trie.save('lmodel_chars.trie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for words\n",
    "import re\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from alphabet_detector import AlphabetDetector\n",
    "ad = AlphabetDetector()\n",
    "ad.only_alphabet_chars(u\"кириллический\", \"CYRILLIC\")\n",
    "clean_tokens=[]\n",
    "for i in all_tokens:\n",
    "    if ad.is_cyrillic(i) and i.isdigit()==False and i!='-':\n",
    "        clean_tokens.append(i)\n",
    "finder = BigramCollocationFinder.from_words(clean_tokens)\n",
    "finder.apply_word_filter(lambda w: w in ('.,:;?!-...!!!?!!?...'))\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "unigrams={}\n",
    "for i in clean_tokens:\n",
    "    unigrams[i]=clean_tokens.count(i)/len(clean_tokens)\n",
    "bigram_probs={}\n",
    "for i in scored:\n",
    "    for k, v in unigrams.items():\n",
    "        if i[0][0] == k:\n",
    "            bigram_probs[i[0][0]+' '+i[0][1]]=i[1]/v\n",
    "import datrie\n",
    "trie = datrie.Trie('йцукенгшщзхъфывапролджэячсмитьбю -ё')\n",
    "for k, v in bigram_probs.items():\n",
    "    trie[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trie.save('lmodel.trie')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
