{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "morph = MorphAnalyzer()\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'hw3_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_json(file, lines=True, encoding='utf-8') for file in files], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_kws, predicted_kws):\n",
    "    assert len(true_kws) == len(predicted_kws)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    jaccards = []\n",
    "    \n",
    "    for i in range(len(true_kws)):\n",
    "        true_kw = set(true_kws[i])\n",
    "        predicted_kw = set(predicted_kws[i])\n",
    "        \n",
    "        tp = len(true_kw & predicted_kw)\n",
    "        union = len(true_kw | predicted_kw)\n",
    "        fp = len(predicted_kw - true_kw)\n",
    "        fn = len(true_kw - predicted_kw)\n",
    "        \n",
    "        if (tp+fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        \n",
    "        if (tp+fn) == 0:\n",
    "            rec = 0\n",
    "        else:\n",
    "            rec = tp / (tp + fn)\n",
    "        if (prec+rec) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = (2*(prec*rec))/(prec+rec)\n",
    "            \n",
    "        jac = tp / union\n",
    "        \n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        jaccards.append(jac)\n",
    "    print('Precision - ', round(np.mean(precisions), 2))\n",
    "    print('Recall - ', round(np.mean(recalls), 2))\n",
    "    print('F1 - ', round(np.mean(f1s), 2))\n",
    "    print('Jaccard - ', round(np.mean(jaccards), 2))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  1.0\n",
      "Recall -  1.0\n",
      "F1 -  1.0\n",
      "Jaccard -  1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация, удаление стоп-слов и нормализация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_norm'] = data['title'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [молодёжный, яблоко, оппозиционный, деятельнос...\n",
       "1                                   [газпром, хватить]\n",
       "2        [бесконечный, партия, четырехмерный, шахматы]\n",
       "3    [экс-депутат, осудить, фальсификация, выбор, о...\n",
       "4    [новый, москва, остаться, территория, экологич...\n",
       "5    [f1, гран-при, сша, пройти, четыре, машина, ст...\n",
       "6    [100, ведущий, политик, россия, февраль, 2018,...\n",
       "7             [закон, культура, принимать, фон, арест]\n",
       "8    [насколько, реальный, газовый, подоплёка, сири...\n",
       "9    [фсб, калужский, область, задержать, четверо, ...\n",
       "Name: title_norm, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_norm'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.11\n",
      "Recall -  0.22\n",
      "F1 -  0.14\n",
      "Jaccard -  0.08\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.13\n",
      "F1 -  0.12\n",
      "Jaccard -  0.07\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'],data['title_norm'].apply(lambda x: x[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [яблоко, молодёжный, который, акция, год, акти...\n",
       "1     [миллиард, газа, год, куб, метр, газпром, добы...\n",
       "2     [год, это, книга, роман, тот, писать, выйти, о...\n",
       "3     [ким, зинаида, видео, год, журналист, суд, дел...\n",
       "4     [площадь, территория, новый, москва, га, котор...\n",
       "5     [гонка, который, команда, место, позиция, два,...\n",
       "6     [место, влияние, рф, позиция, глава, россия, п...\n",
       "7     [культура, закон, который, сфера, стд, разрабо...\n",
       "8     [газопровод, сирия, год, турция, газа, россия,...\n",
       "9     [участник, рф, террористический, организация, ...\n",
       "10    [тихон, стихомант, это, журибеда, старик, врем...\n",
       "11    [жильё, метр, кв, год, миллион, жилищный, насе...\n",
       "12    [российский, театр, зритель, стать, кино, год,...\n",
       "13    [фестиваль, революция, фильм, ленин, награда, ...\n",
       "14    [вечер, фёдоров, балашов, книга, который, викт...\n",
       "15    [который, сирийский, переговоры, резолюция, оо...\n",
       "16    [рф, суд, кс, запрос, постановление, право, че...\n",
       "17    [электромобиль, год, тысяча, кобальт, который,...\n",
       "18    [хороший, фильм, оскар, год, один, главный, ст...\n",
       "19    [сабина, нюрбургринг, трасса, fia, wtcc, участ...\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0] for word in words if word and word not in stops]\n",
    "    words = [word.normal_form for word in words if word.tag.POS == 'NOUN']\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm'] = data['content'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.25\n",
      "F1 -  0.16\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [яблоко, акция, год, активист, деятельность, п...\n",
       "1    [миллиард, газа, год, куб, метр, газпром, добы...\n",
       "2    [год, книга, роман, мир, перевод, стихотворени...\n",
       "3    [ким, зинаида, видео, год, журналист, суд, дел...\n",
       "4    [площадь, территория, москва, га, столица, тин...\n",
       "5    [гонка, команда, место, позиция, круг, чемпион...\n",
       "6    [место, влияние, рф, позиция, глава, россия, п...\n",
       "7    [культура, закон, сфера, концепция, проект, из...\n",
       "8    [газопровод, сирия, год, турция, газа, россия,...\n",
       "9    [участник, рф, организация, государство, облас...\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content_norm'].apply(lambda x: [x[0] for x in Counter(x).most_common(10)]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content_norm_str'] = data['content_norm'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(data['content_norm_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for i,word in enumerate(tfidf.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_vectors = tfidf.transform(data['content_norm_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [[id2word[w] for w in top] for top in texts_vectors.toarray().argsort()[:,:-11:-1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['яблоко',\n",
       "  'активист',\n",
       "  'акция',\n",
       "  'дарья',\n",
       "  'деятельность',\n",
       "  'молодая человек',\n",
       "  'политика',\n",
       "  'виктор',\n",
       "  'тимур',\n",
       "  'репрессия'],\n",
       " ['миллиард куб',\n",
       "  'куб метр',\n",
       "  'куб',\n",
       "  'газпром',\n",
       "  'газа',\n",
       "  'миллиард',\n",
       "  'добыча',\n",
       "  'добыча газа',\n",
       "  'метр',\n",
       "  'холдинг'],\n",
       " ['роман',\n",
       "  'книга',\n",
       "  'жанр',\n",
       "  'стихотворение',\n",
       "  'читатель',\n",
       "  'перевод',\n",
       "  'год',\n",
       "  'поэзия',\n",
       "  'произведение',\n",
       "  'том']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.13\n",
      "Recall -  0.25\n",
      "F1 -  0.16\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:  \n",
    "Precision -  0.13  \n",
    "Recall -  0.24  \n",
    "F1 -  0.16  \n",
    "Jaccard -  0.09  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытки привлечь сторонние библиотеки: rutermextract, multi_rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content_norm</th>\n",
       "      <th>title_norm</th>\n",
       "      <th>content_norm_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Многие интересуются, зачем нужна «Яблоку» моло...</td>\n",
       "      <td>[яблоко, молодежь, молодежное яблоко]</td>\n",
       "      <td></td>\n",
       "      <td>\"Молодежное \"Яблоко\": оппозиционная деятельнос...</td>\n",
       "      <td>http://www.ng.ru/ng_politics/2017-04-18/11_697...</td>\n",
       "      <td>[яблоко, фракция, задача, яблоко, привлечение,...</td>\n",
       "      <td>[молодёжный, яблоко, оппозиционный, деятельнос...</td>\n",
       "      <td>яблоко фракция задача яблоко привлечение молод...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вчера «Газпром» снизил верхнюю планку прогноза...</td>\n",
       "      <td>[газпром, газ]</td>\n",
       "      <td></td>\n",
       "      <td>\"Газпрома\" на всех не хватит</td>\n",
       "      <td>http://www.ng.ru/economics/2008-04-03/1_gazpro...</td>\n",
       "      <td>[газпром, планка, прогноз, добыча, газа, год, ...</td>\n",
       "      <td>[газпром, хватить]</td>\n",
       "      <td>газпром планка прогноз добыча газа год год кон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Долголетний труд Евгения Витковского на ниве п...</td>\n",
       "      <td>[франсуа рабле, сервантес, шекспир, конан дойл...</td>\n",
       "      <td>Евгений Витковский о том, как Босх протягивает...</td>\n",
       "      <td>Бесконечная партия в четырехмерные  шахматы</td>\n",
       "      <td>http://www.ng.ru/person/2018-03-22/10_927_vitk...</td>\n",
       "      <td>[труд, евгений, витковский, нива, перевод, кач...</td>\n",
       "      <td>[бесконечный, партия, четырехмерный, шахматы]</td>\n",
       "      <td>труд евгений витковский нива перевод качество ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Ленинском районном суде продолжаются слушани...</td>\n",
       "      <td>[владивосток, суд, ким, футина, выборы, боевое...</td>\n",
       "      <td>Фигурантке уголовного дела о фальсификации выб...</td>\n",
       "      <td>Экс-депутат, осужденная за фальсификацию выбор...</td>\n",
       "      <td>http://www.ng.ru/regions/2018-01-10/100_vladiv...</td>\n",
       "      <td>[суд, слушание, дело, экс-депутат, дума, влади...</td>\n",
       "      <td>[экс-депутат, осудить, фальсификация, выбор, о...</td>\n",
       "      <td>суд слушание дело экс-депутат дума владивосток...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В 2012 году российская столица резко увеличила...</td>\n",
       "      <td>[новая москва, подмосковье, благоустройство, т...</td>\n",
       "      <td>Лучшие проекты благоустройства общественных пр...</td>\n",
       "      <td>Новая Москва останется территорией экологическ...</td>\n",
       "      <td>http://www.ng.ru/ng_stolitsa/2017-11-10/10_711...</td>\n",
       "      <td>[год, столица, размер, результат, присоединени...</td>\n",
       "      <td>[новый, москва, остаться, территория, экологич...</td>\n",
       "      <td>год столица размер результат присоединение час...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Многие интересуются, зачем нужна «Яблоку» моло...   \n",
       "1  Вчера «Газпром» снизил верхнюю планку прогноза...   \n",
       "2  Долголетний труд Евгения Витковского на ниве п...   \n",
       "3  В Ленинском районном суде продолжаются слушани...   \n",
       "4  В 2012 году российская столица резко увеличила...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0              [яблоко, молодежь, молодежное яблоко]   \n",
       "1                                     [газпром, газ]   \n",
       "2  [франсуа рабле, сервантес, шекспир, конан дойл...   \n",
       "3  [владивосток, суд, ким, футина, выборы, боевое...   \n",
       "4  [новая москва, подмосковье, благоустройство, т...   \n",
       "\n",
       "                                             summary  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  Евгений Витковский о том, как Босх протягивает...   \n",
       "3  Фигурантке уголовного дела о фальсификации выб...   \n",
       "4  Лучшие проекты благоустройства общественных пр...   \n",
       "\n",
       "                                               title  \\\n",
       "0  \"Молодежное \"Яблоко\": оппозиционная деятельнос...   \n",
       "1                       \"Газпрома\" на всех не хватит   \n",
       "2        Бесконечная партия в четырехмерные  шахматы   \n",
       "3  Экс-депутат, осужденная за фальсификацию выбор...   \n",
       "4  Новая Москва останется территорией экологическ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.ng.ru/ng_politics/2017-04-18/11_697...   \n",
       "1  http://www.ng.ru/economics/2008-04-03/1_gazpro...   \n",
       "2  http://www.ng.ru/person/2018-03-22/10_927_vitk...   \n",
       "3  http://www.ng.ru/regions/2018-01-10/100_vladiv...   \n",
       "4  http://www.ng.ru/ng_stolitsa/2017-11-10/10_711...   \n",
       "\n",
       "                                        content_norm  \\\n",
       "0  [яблоко, фракция, задача, яблоко, привлечение,...   \n",
       "1  [газпром, планка, прогноз, добыча, газа, год, ...   \n",
       "2  [труд, евгений, витковский, нива, перевод, кач...   \n",
       "3  [суд, слушание, дело, экс-депутат, дума, влади...   \n",
       "4  [год, столица, размер, результат, присоединени...   \n",
       "\n",
       "                                          title_norm  \\\n",
       "0  [молодёжный, яблоко, оппозиционный, деятельнос...   \n",
       "1                                 [газпром, хватить]   \n",
       "2      [бесконечный, партия, четырехмерный, шахматы]   \n",
       "3  [экс-депутат, осудить, фальсификация, выбор, о...   \n",
       "4  [новый, москва, остаться, территория, экологич...   \n",
       "\n",
       "                                    content_norm_str  \n",
       "0  яблоко фракция задача яблоко привлечение молод...  \n",
       "1  газпром планка прогноз добыча газа год год кон...  \n",
       "2  труд евгений витковский нива перевод качество ...  \n",
       "3  суд слушание дело экс-депутат дума владивосток...  \n",
       "4  год столица размер результат присоединение час...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rutermextract import TermExtractor\n",
    "term_extractor = TermExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terms(text):\n",
    "    l=[]\n",
    "    for term in term_extractor(text):\n",
    "        if term.count>=3:\n",
    "            l.append(term.normalized)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasel\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "data['term_extract']=data['content'].apply(extract_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.16\n",
      "Recall -  0.21\n",
      "F1 -  0.15\n",
      "Jaccard -  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['term_extract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_rake import Rake\n",
    "rake = Rake(language_code='ru')\n",
    "def extract_rake(text):\n",
    "    l=[]\n",
    "    for keyword in rake.apply(text):\n",
    "        if keyword[1]>=5:\n",
    "            for i in keyword[0].split():\n",
    "                l.append(i)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['новым',\n",
       " 'витком',\n",
       " 'цен',\n",
       " 'озвучил',\n",
       " 'летом',\n",
       " 'прошлого',\n",
       " 'очередные',\n",
       " 'заявления',\n",
       " 'представителей',\n",
       " 'ранее',\n",
       " 'озвученных',\n",
       " 'прогнозов',\n",
       " 'осваивать',\n",
       " 'новые',\n",
       " 'регионы',\n",
       " 'рукаве',\n",
       " 'сильный',\n",
       " 'козырь',\n",
       " 'шельфе',\n",
       " 'баренцева',\n",
       " 'моря',\n",
       " 'периоду',\n",
       " 'увеличат',\n",
       " 'производство',\n",
       " 'согласно',\n",
       " 'экспертным',\n",
       " 'оценкам',\n",
       " 'удар',\n",
       " 'попадут',\n",
       " 'прежде',\n",
       " 'регулируемым',\n",
       " 'федеральной',\n",
       " 'службой',\n",
       " 'условиях',\n",
       " 'рыночного',\n",
       " 'ценообразования',\n",
       " 'концерн',\n",
       " 'собирается',\n",
       " 'добывать',\n",
       " 'холдинг',\n",
       " 'планирует',\n",
       " 'вкладываться',\n",
       " 'общее',\n",
       " 'производство',\n",
       " 'газа',\n",
       " 'треть',\n",
       " 'добываемого',\n",
       " 'объема',\n",
       " 'уточнил',\n",
       " 'предыдущий',\n",
       " 'прогноз',\n",
       " 'минэкономразвития',\n",
       " 'добыча',\n",
       " 'газа',\n",
       " 'суммарная',\n",
       " 'добыча',\n",
       " 'газа',\n",
       " 'сложно',\n",
       " 'оценить',\n",
       " 'однозначно',\n",
       " 'подкорректированные',\n",
       " 'планы',\n",
       " 'выглядят',\n",
       " 'стадии',\n",
       " 'падающей',\n",
       " 'добычи',\n",
       " 'среднемировому',\n",
       " 'уровню',\n",
       " 'потребители',\n",
       " 'обеспечить',\n",
       " 'независимые',\n",
       " 'производители',\n",
       " 'резко',\n",
       " 'должны',\n",
       " 'вырасти',\n",
       " 'прибыльные',\n",
       " 'экспортные',\n",
       " 'поставки',\n",
       " 'внутреннее',\n",
       " 'потребление',\n",
       " 'придется',\n",
       " 'внутреннее',\n",
       " 'потребление']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_rake(data['content'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rake']=data['content'].apply(extract_rake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.01\n",
      "Recall -  0.14\n",
      "F1 -  0.02\n",
      "Jaccard -  0.01\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], data['rake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что ничего особенного из этой затеи не получилось. Попробуем продолжить с графами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kws(text, top=5, window_size=5, random_p=0.1):\n",
    "\n",
    "    vocab = set(text)\n",
    "    word2id = {w:i for i, w in enumerate(vocab)}\n",
    "    id2word = {i:w for i, w in enumerate(vocab)}\n",
    "    # преобразуем слова в индексы для удобства\n",
    "    ids = [word2id[word] for word in text]\n",
    "\n",
    "    # создадим матрицу совстречаемости\n",
    "    m = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # пройдемся окном по всему тексту\n",
    "    for i in range(0, len(ids), window_size):\n",
    "        window = ids[i:i+window_size]\n",
    "        # добавим единичку всем парам слов в этом окне\n",
    "        for j, k in combinations(window, 2):\n",
    "            # чтобы граф был ненаправленный \n",
    "            m[j][k] += 1\n",
    "            m[k][j] += 1\n",
    "    \n",
    "    # нормализуем строки, чтобы получилась вероятность перехода\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i] /= np.sum(m[i])\n",
    "    \n",
    "    # случайно выберем первое слова, а затем будет выбирать на основе полученых распределений\n",
    "    # сделаем так 5 раз и добавим каждое слово в счетчик\n",
    "    # чтобы не забиться в одном круге, иногда будет перескакивать на случайное слово\n",
    "    \n",
    "    c = Counter()\n",
    "    # начнем с абсолютного случайно выбранного элемента\n",
    "    n = np.random.choice(len(vocab))\n",
    "    for i in range(500): # если долго считается, можно уменьшить число проходов\n",
    "        \n",
    "        # c вероятностью random_p \n",
    "        # перескакиваем на другой узел\n",
    "        go_random = np.random.choice([0, 1], p=[1-random_p, random_p])\n",
    "        if go_random:\n",
    "            n = np.random.choice(len(vocab))\n",
    "        \n",
    "        n = take_step(n, m)\n",
    "        # записываем узлы, в которых были\n",
    "        c.update([n])\n",
    "    \n",
    "    # вернем топ-N наиболее часто встретившихся сл\n",
    "    return [id2word[i] for i, count in c.most_common(top)]\n",
    "\n",
    "def take_step(n, matrix):\n",
    "    rang = len(matrix[n])\n",
    "    # выбираем узел из заданного интервала, на основе распределения из матрицы совстречаемости\n",
    "    next_n = np.random.choice(range(rang), p=matrix[n])\n",
    "    return next_n\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keywords_rw = data['content_norm'].apply(lambda x: get_kws(x, 10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.11\n",
      "Recall -  0.21\n",
      "F1 -  0.14\n",
      "Jaccard -  0.08\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keywords_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [яблоко, год, политика, акция, виктор, россия,...\n",
       "1    [миллиард, добыча, газа, газпром, год, куб, пр...\n",
       "2    [год, стихотворение, книга, роман, александр, ...\n",
       "3    [ким, видео, год, журналист, зинаида, адвокат,...\n",
       "4    [площадь, территория, москва, га, парка, тинао...\n",
       "5    [гонка, команда, заезд, позиция, пилот, машина...\n",
       "6    [место, влияние, глава, рф, позиция, институт,...\n",
       "7    [культура, сфера, закон, концепция, изменение,...\n",
       "8    [год, поток, газа, катар, европа, газопровод, ...\n",
       "9    [рф, организация, участник, фсб, область, март...\n",
       "Name: content_norm, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_rw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(text, window_size=5):\n",
    "    vocab = set(text)\n",
    "    word2id = {w:i for i, w in enumerate(vocab)}\n",
    "    id2word = {i:w for i, w in enumerate(vocab)}\n",
    "    # преобразуем слова в индексы для удобства\n",
    "    ids = [word2id[word] for word in text]\n",
    "\n",
    "    # создадим матрицу совстречаемости\n",
    "    m = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # пройдемся окном по всему тексту\n",
    "    for i in range(0, len(ids), window_size):\n",
    "        window = ids[i:i+window_size]\n",
    "        # добавим единичку всем парам слов в этом окне\n",
    "        for j, k in combinations(window, 2):\n",
    "            # чтобы граф был ненаправленный \n",
    "            m[j][k] += 1\n",
    "            m[k][j] += 1\n",
    "    \n",
    "    return m, id2word\n",
    "\n",
    "def some_centrality_measure(text, window_size=5, topn=5):\n",
    "    \n",
    "    matrix, id2word = build_matrix(text, window_size)\n",
    "    G = nx.from_numpy_array(matrix)\n",
    "    # тут можно поставить любую метрику\n",
    "    node2measure = dict(nx.degree(G))\n",
    "    \n",
    "    return [id2word[index] for index,measure in sorted(node2measure.items(), key=lambda x: -x[1])[:topn]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что-то заработало"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способ 1: поменять аргументы centrality measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "keyword_nx = data['content_norm'].apply(lambda x: some_centrality_measure(x, 10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.18\n",
      "Recall -  0.17\n",
      "F1 -  0.17\n",
      "Jaccard -  0.1\n"
     ]
    }
   ],
   "source": [
    "evaluate(data['keywords'], keyword_nx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
